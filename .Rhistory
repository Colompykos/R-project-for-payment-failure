# Caractérisation des clusters
cluster_profiles_5 <- data_clean %>%
group_by(cluster_5) %>%
summarise(
Taille = n(),
Taux_defaut = mean(defaut == "Oui") * 100,
Age_moyen = mean(age, na.rm = TRUE),
Age_median = median(age, na.rm = TRUE),
Revenu_moyen = mean(revenus, na.rm = TRUE),
Revenu_median = median(revenus, na.rm = TRUE),
Dette_credit_moyenne = mean(debcred, na.rm = TRUE),
Dette_carte_moyenne = mean(debcarte, na.rm = TRUE),
Autres_dettes_moyenne = mean(autres, na.rm = TRUE),
Emploi_moyen = mean(emploi, na.rm = TRUE)
)
print("Profils des clusters (K=5):")
print(cluster_profiles_5)
# Visualisations pour K=5
# Distribution des défauts
ggplot(data_clean, aes(x = cluster_5, fill = defaut)) +
geom_bar(position = "fill") +
scale_y_continuous(labels = scales::percent) +
labs(title = "Distribution des défauts par cluster (K=5)",
x = "Cluster",
y = "Proportion") +
theme_minimal()
# Distribution de l'éducation par cluster
ggplot(data_clean, aes(x = education, fill = cluster_5)) +
geom_bar(position = "dodge") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Distribution de l'éducation par cluster_5")
# Boîtes à moustaches des variables numériques
for(var in variables_num) {
print(
ggplot(data_clean, aes_string(x = "cluster_5", y = var, fill = "cluster_5")) +
geom_boxplot() +
labs(title = paste("Distribution de", var, "par cluster (K=5)")) +
theme_minimal()
)
}
# Évaluation statistique pour K=5
print("Tests statistiques pour K=5:")
for(var in variables_num) {
print(paste("ANOVA pour", var))
print(summary(aov(as.formula(paste(var, "~ cluster_5")), data = data_clean)))
}
# Calcul de la silhouette pour K=5
sil_5 <- silhouette(kmeans_5$cluster, dist(data_scaled))
plot(sil_5, main = "Silhouette plot (K=5)")
print(paste("Silhouette moyenne (K=5):", mean(sil_5[,3])))
# Tests de Kruskal-Wallis pour toutes les variables numériques
variables_test <- c("age", "revenus", "debcred", "debcarte", "autres", "emploi")
# Fonction pour faire tous les tests statistiques
run_statistical_tests <- function(data, cluster_var) {
results <- list()
# Tests Kruskal-Wallis
for(var in variables_test) {
formula <- as.formula(paste(var, "~", cluster_var))
test_result <- kruskal.test(formula, data = data)
results[[paste("kruskal", var)]] <- test_result
}
# Test Chi-carré pour variables catégorielles
chi_education <- chisq.test(table(data$education, data[[cluster_var]]))
chi_defaut <- chisq.test(table(data$defaut, data[[cluster_var]]))
results[["chi_education"]] <- chi_education
results[["chi_defaut"]] <- chi_defaut
return(results)
}
# Exécution des tests pour K=2, K=3 et K=5
results_k2 <- run_statistical_tests(data_clean, "cluster_2")
results_k3 <- run_statistical_tests(data_clean, "cluster_3")
results_k5 <- run_statistical_tests(data_clean, "cluster_5")
comparative_analysis <- data.frame(
K = rep(c(2, 3, 5), each = length(variables_test)),
Variable = rep(variables_test, 3),
Kruskal_pvalue = c(
sapply(results_k2[grep("kruskal", names(results_k2))], function(x) x$p.value),
sapply(results_k3[grep("kruskal", names(results_k3))], function(x) x$p.value),
sapply(results_k5[grep("kruskal", names(results_k5))], function(x) x$p.value)
)
)
# Validation de la qualité des clusters
cluster_quality <- data.frame(
K = c(2, 3, 5),
Within_SS = c(kmeans_2$tot.withinss, kmeans_3$tot.withinss, kmeans_5$tot.withinss),
Between_SS = c(kmeans_2$betweenss, kmeans_3$betweenss, kmeans_5$betweenss),
Total_SS = c(kmeans_2$totss, kmeans_3$totss, kmeans_5$totss),
Silhouette = c(mean(sil_2[,3]), mean(sil_3[,3]), mean(sil_5[,3]))
)
# Calcul des ratios de variance expliquée
cluster_quality$Explained_Variance_Ratio <- cluster_quality$Between_SS / cluster_quality$Total_SS
cluster_comparison <- data.frame(
K = c(2, 3, 5),
Clusters_Size_Range = c(
paste(range(table(data_clean$cluster_2)), collapse="-"),
paste(range(table(data_clean$cluster_3)), collapse="-"),
paste(range(table(data_clean$cluster_5)), collapse="-")
),
Defaut_Rate_Range = c(
paste(range(round(cluster_profiles_2$Taux_defaut, 2)), collapse="-"),
paste(range(round(cluster_profiles_3$Taux_defaut, 2)), collapse="-"),
paste(range(round(cluster_profiles_5$Taux_defaut, 2)), collapse="-")
),
Silhouette_Score = round(cluster_quality$Silhouette, 3),
Explained_Variance = round(cluster_quality$Explained_Variance_Ratio, 3)
)
# Affichage des résultats
print("Analyse comparative des configurations de clustering:")
print(cluster_comparison)
print("\nTests statistiques significatifs (p < 0.05):")
print(subset(comparative_analysis, Kruskal_pvalue < 0.05))
print("\nQualité des clusters:")
print(cluster_quality)
# Visualisation comparative des silhouettes
ggplot(cluster_quality, aes(x = as.factor(K), y = Silhouette)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Comparaison des scores de silhouette",
x = "Nombre de clusters (K)",
y = "Score de silhouette moyen") +
theme_minimal()
# Visualisation de la variance expliquée
ggplot(cluster_quality, aes(x = as.factor(K), y = Explained_Variance_Ratio)) +
geom_bar(stat = "identity", fill = "darkred") +
labs(title = "Ratio de variance expliquée par configuration",
x = "Nombre de clusters (K)",
y = "Ratio de variance expliquée") +
theme_minimal()
# Ensemble d'apprentissage de 80% du data
data_EA<- data[1:4800,]
# Ensemble de test de 20% du data
data_ET<- data[4801:6000,]
# Suppression de la variable client (variable unique)
data_EA <- subset(data_EA, select=-client)
# Apprentissage arbre
tree1 <- rpart(defaut~., data_EA)
# Affichage graphique : tracage des arcs par la fonction plot.rpart()
plot(tree1)
# Ajout du texte au graphique par la fonction text.rpart()
text(tree1, pretty = 0)
# affichage avec la librairie rpart.plot
rpart.plot(tree1, cex=0.6)
# Selection d'attribut par Coefficient de Gini et effectif minimal d'un noeud de 10
tree_rp1 <- rpart(defaut~., data_EA, parms = list(split = "gini"), control = rpart.control(minbucket = 10))
plot(tree_rp1)
text(tree_rp1, pretty = 0)
# Selection d'attribut par Coefficient de Gini et effectif minimal d'un noeud de 5
tree_rp2 <- rpart(defaut~., data_EA, parms = list(split = "gini"), control = rpart.control(minbucket = 5))
plot(tree_rp2)
text(tree_rp2, pretty = 0)
# Selection d'attribut par Information Gain et effectif minimal d'un noeud de 10
tree_rp3 <- rpart(defaut~., data_EA, parms = list(split = "information"), control = rpart.control(minbucket = 10))
plot(tree_rp3)
text(tree_rp3, pretty = 0)
# Selection d'attribut par Information Gain et effectif minimal d'un noeud de 5
tree_rp4 <- rpart(defaut~., data_EA, parms = list(split = "information"), control = rpart.control(minbucket = 5))
plot(tree_rp4)
text(tree_rp4, pretty = 0)
# Affichage des arbres rpart() avec rpart.plot() pour plus de lisibilité
rpart.plot(tree_rp1)
rpart.plot(tree_rp2, cex=0.7)
rpart.plot(tree_rp3)
rpart.plot(tree_rp4, cex=0.7)
# Apprentissage arbre
tree2 <- tree(defaut~., data=data_EA)
# Affichage graphique : tracage des arcs par la fonction plot.tree()
plot(tree2)
# Ajout du texte au graphique par la fonction text.tree()
text(tree2, pretty=0)
# Apprentissage 1er parametrage pour tree()
tree_tr1 <- tree(defaut~., data_EA, split = "deviance", control = tree.control(nrow(data_EA), mincut = 10))
plot(tree_tr1)
text(tree_tr1, pretty = 0)
# Apprentissage 2nd parametrage pour tree()
tree_tr2 <- tree(defaut~., data_EA, split = "deviance", control = tree.control(nrow(data_EA), mincut = 5))
plot(tree_tr2)
text(tree_tr2, pretty = 0)
# Apprentissage 3eme parametrage pour tree() / overlapping text, making it unreadable. The tree has too many splits and the nodes are very close to each other
tree_tr3 <- tree(defaut~., data_EA, split = "gini", control = tree.control(nrow(data_EA), mincut = 10))
plot(tree_tr3)
text(tree_tr3, pretty = 0)
# Apprentissage 4eme parametrage pour tree()
tree_tr4 <- tree(defaut~., data_EA, split = "gini", control = tree.control(nrow(data_EA), mincut = 5))
plot(tree_tr4)
text(tree_tr4, pretty = 0)
##  Rpart cases
# Sans paramétrage
# Application de l'arbre 'tree1' a l'ensemble de test 'data_ET'
test_tree1 <- predict(tree1, data_ET, type="class")
# Avec paramétrage
# Application de l'arbre 'tree_rp1' a l'ensemble de test 'data_ET'
test_rp1 <- predict(tree_rp1, data_ET, type="class")
# Application de l'arbre 'tree_rp2' a l'ensemble de test 'data_ET'
test_rp2 <- predict(tree_rp2, data_ET, type="class")
# Application de l'arbre 'tree_rp3' a l'ensemble de test 'data_ET'
test_rp3 <- predict(tree_rp3, data_ET, type="class")
# Application de l'arbre 'tree_rp4' a l'ensemble de test 'data_ET'
test_rp4 <- predict(tree_rp4, data_ET, type="class")
## tree cases
# Sans paramétrage
# Application de l'arbre 'tree2' a l'ensemble de test 'data_ET'
test_tree2 <- predict(tree2, data_ET, type="class")
# Avec paramétrage
# Test  1
test_tr1 <- predict(tree_tr1, data_ET, type="class")
# Test  2
test_tr2 <- predict(tree_tr2, data_ET, type="class")
# Test  3
test_tr3 <- predict(tree_tr3, data_ET, type="class")
# Test  4
test_tr4 <- predict(tree_tr4, data_ET, type="class")
# Comparaison des repartitions des predictions
table(test_tree1)
table(test_rp1)
table(test_rp2)
table(test_rp3)
table(test_rp4)
table(test_tree2)
table(test_tr1)
table(test_tr2)
table(test_tr3)
table(test_tr4)
# Créer des tables pour chaque ensemble de prédictions
table_tree1 <- table(test_tree1)
table_rp1 <- table(test_rp1)
table_rp2 <- table(test_rp2)
table_rp3 <- table(test_rp3)
table_rp4 <- table(test_rp4)
table_tree2 <- table(test_tree2)
table_tr1 <- table(test_tr1)
table_tr2 <- table(test_tr2)
table_tr3 <- table(test_tr3)
table_tr4 <- table(test_tr4)
# Combiner les résultats dans un dataframe
results <- data.frame(
Test = c("test_tree1", "test_rp1", "test_rp2", "test_rp3", "test_rp4", "test_tree2", "test_tr1", "test_tr2", "test_tr3", "test_tr4"),
Non = c(table_tree1["Non"], table_rp1["Non"], table_rp2["Non"], table_rp3["Non"], table_rp4["Non"], table_tree2["Non"], table_tr1["Non"], table_tr2["Non"], table_tr3["Non"], table_tr4["Non"]),
Oui = c(table_tree1["Oui"], table_rp1["Oui"], table_rp2["Oui"], table_rp3["Oui"], table_rp4["Oui"], table_tree2["Oui"], table_tr1["Oui"], table_tr2["Oui"], table_tr3["Oui"], table_tr4["Oui"])
)
# Afficher le tableau
print(results)
# Rpart cases
taux_tree1 <- nrow(data_ET[data_ET$defaut == test_tree1, ]) / nrow(data_ET)
taux_rp1 <- nrow(data_ET[data_ET$defaut == test_rp1, ]) / nrow(data_ET)
taux_rp2 <- nrow(data_ET[data_ET$defaut == test_rp2, ]) / nrow(data_ET)
taux_rp3 <- nrow(data_ET[data_ET$defaut == test_rp3, ]) / nrow(data_ET)
taux_rp4 <- nrow(data_ET[data_ET$defaut == test_rp4, ]) / nrow(data_ET)
cat("Taux pour test_tree1:", taux_tree1, "\n")
cat("Taux pour test_rp1:", taux_rp1, "\n")
cat("Taux pour test_rp2:", taux_rp2, "\n")
cat("Taux pour test_rp3:", taux_rp3, "\n")
cat("Taux pour test_rp4:", taux_rp4, "\n")
# Tree cases
taux_tree2 <- nrow(data_ET[data_ET$defaut == test_tree2, ]) / nrow(data_ET)
taux_tr1 <- nrow(data_ET[data_ET$defaut == test_tr1, ]) / nrow(data_ET)
taux_tr2 <- nrow(data_ET[data_ET$defaut == test_tr2, ]) / nrow(data_ET)
taux_tr3 <- nrow(data_ET[data_ET$defaut == test_tr3, ]) / nrow(data_ET)
taux_tr4 <- nrow(data_ET[data_ET$defaut == test_tr4, ]) / nrow(data_ET)
cat("Taux pour test_tree2:", taux_tree2, "\n")
cat("Taux pour test_tr1:", taux_tr1, "\n")
cat("Taux pour test_tr2:", taux_tr2, "\n")
cat("Taux pour test_tr3:", taux_tr3, "\n")
cat("Taux pour test_tr4:", taux_tr4, "\n")
# Matrice de confusion pour 'tree1'
mc_tree1 <- table(data_ET$defaut, test_tree1)
print(mc_tree1)
# Rappel
mc_tree1[2,2]/(mc_tree1[2,2]+mc_tree1[2,1])
# Spécificité
mc_tree1[1,1]/(mc_tree1[1,1]+mc_tree1[1,2])
# Précision
mc_tree1[2,2]/(mc_tree1[2,2]+mc_tree1[1,2])
# Taux de Vrais Négatifs
mc_tree1[1,1]/(mc_tree1[1,1]+mc_tree1[2,1])
# Matrice de confusion pour 'test_rp1'
mc_rp1 <- table(data_ET$defaut, test_rp1)
print(mc_rp1)
# Rappel
mc_rp1[2,2]/(mc_rp1[2,2]+mc_rp1[2,1])
# Spécificité
mc_rp1[1,1]/(mc_rp1[1,1]+mc_rp1[1,2])
# Précision
mc_rp1[2,2]/(mc_rp1[2,2]+mc_rp1[1,2])
# Taux de Vrais Négatifs
mc_rp1[1,1]/(mc_rp1[1,1]+mc_rp1[2,1])
# Matrice de confusion pour 'test_rp2'
mc_rp2 <- table(data_ET$defaut, test_rp2)
print(mc_rp2)
# Rappel
mc_rp2[2,2]/(mc_rp2[2,2]+mc_rp2[2,1])
# Spécificité
mc_rp2[1,1]/(mc_rp2[1,1]+mc_rp2[1,2])
# Précision
mc_rp2[2,2]/(mc_rp2[2,2]+mc_rp2[1,2])
# Taux de Vrais Négatifs
mc_rp2[1,1]/(mc_rp2[1,1]+mc_rp2[2,1])
# Matrice de confusion pour 'test_rp3'
mc_rp3 <- table(data_ET$defaut, test_rp3)
print(mc_rp3)
# Rappel
mc_rp3[2,2]/(mc_rp3[2,2]+mc_rp3[2,1])
# Spécificité
mc_rp3[1,1]/(mc_rp3[1,1]+mc_rp3[1,2])
# Précision
mc_rp3[2,2]/(mc_rp3[2,2]+mc_rp3[1,2])
# Taux de Vrais Négatifs
mc_rp3[1,1]/(mc_rp3[1,1]+mc_rp3[2,1])
# Matrice de confusion pour 'test_rp4'
mc_rp4 <- table(data_ET$defaut, test_rp4)
print(mc_rp4)
# Rappel
mc_rp4[2,2]/(mc_rp4[2,2]+mc_rp4[2,1])
# Spécificité
mc_rp4[1,1]/(mc_rp4[1,1]+mc_rp4[1,2])
# Précision
mc_rp4[2,2]/(mc_rp4[2,2]+mc_rp4[1,2])
# Taux de Vrais Négatifs
mc_rp4[1,1]/(mc_rp4[1,1]+mc_rp4[2,1])
# Matrice de confusion pour 'test_tree2'
mc_tree2 <- table(data_ET$defaut, test_tree2)
print(mc_tree2)
# Rappel
mc_tree2[2,2]/(mc_tree2[2,2]+mc_tree2[2,1])
# Spécificité
mc_tree2[1,1]/(mc_tree2[1,1]+mc_tree2[1,2])
# Précision
mc_tree2[2,2]/(mc_tree2[2,2]+mc_tree2[1,2])
# Taux de Vrais Négatifs
mc_tree2[1,1]/(mc_tree2[1,1]+mc_tree2[2,1])
# Matrice de confusion pour 'test_tr1'
mc_tr1 <- table(data_ET$defaut, test_tr1)
print(mc_tr1)
# Rappel
mc_tr1[2,2]/(mc_tr1[2,2]+mc_tr1[2,1])
# Spécificité
mc_tr1[1,1]/(mc_tr1[1,1]+mc_tr1[1,2])
# Précision
mc_tr1[2,2]/(mc_tr1[2,2]+mc_tr1[1,2])
# Taux de Vrais Négatifs
mc_tr1[1,1]/(mc_tr1[1,1]+mc_tr1[2,1])
# Matrice de confusion pour 'test_tr2'
mc_tr2 <- table(data_ET$defaut, test_tr2)
print(mc_tr2)
# Rappel
mc_tr2[2,2]/(mc_tr2[2,2]+mc_tr2[2,1])
# Spécificité
mc_tr2[1,1]/(mc_tr2[1,1]+mc_tr2[1,2])
# Précision
mc_tr2[2,2]/(mc_tr2[2,2]+mc_tr2[1,2])
# Taux de Vrais Négatifs
mc_tr2[1,1]/(mc_tr2[1,1]+mc_tr2[2,1])
# Matrice de confusion pour 'test_tr3'
mc_tr3 <- table(data_ET$defaut, test_tr3)
print(mc_tr3)
# Rappel
mc_tr3[2,2]/(mc_tr3[2,2]+mc_tr3[2,1])
# Spécificité
mc_tr3[1,1]/(mc_tr3[1,1]+mc_tr3[1,2])
# Précision
mc_tr3[2,2]/(mc_tr3[2,2]+mc_tr3[1,2])
# Taux de Vrais Négatifs
mc_tr3[1,1]/(mc_tr3[1,1]+mc_tr3[2,1])
# Matrice de confusion pour 'test_tr4'
mc_tr4 <- table(data_ET$defaut, test_tr4)
print(mc_tr4)
# Rappel
mc_tr4[2,2]/(mc_tr4[2,2]+mc_tr4[2,1])
# Spécificité
mc_tr4[1,1]/(mc_tr4[1,1]+mc_tr4[1,2])
# Précision
mc_tr4[2,2]/(mc_tr4[2,2]+mc_tr4[1,2])
# Taux de Vrais Négatifs
mc_tr4[1,1]/(mc_tr4[1,1]+mc_tr4[2,1])
# Création d'une fonction pour calculer les métriques
calculate_metrics <- function(confusion_matrix) {
recall <- confusion_matrix[2,2] / (confusion_matrix[2,2] + confusion_matrix[2,1])
specificity <- confusion_matrix[1,1] / (confusion_matrix[1,1] + confusion_matrix[1,2])
precision <- confusion_matrix[2,2] / (confusion_matrix[2,2] + confusion_matrix[1,2])
tnr <- confusion_matrix[1,1] / (confusion_matrix[1,1] + confusion_matrix[2,1])
return(c(recall, specificity, precision, tnr))
}
# Création du dataframe avec tous les résultats
models_metrics <- data.frame(
Model = c("tree1", "rp1", "rp2", "rp3", "rp4",
"tree2", "tr1", "tr2", "tr3", "tr4"),
Recall = NA,
Specificity = NA,
Precision = NA,
TNR = NA
)
# Liste des matrices de confusion
confusion_matrices <- list(
mc_tree1, mc_rp1, mc_rp2, mc_rp3, mc_rp4,
mc_tree2, mc_tr1, mc_tr2, mc_tr3, mc_tr4
)
# Remplissage du dataframe avec les métriques
for(i in 1:length(confusion_matrices)) {
metrics <- calculate_metrics(confusion_matrices[[i]])
models_metrics[i, 2:5] <- metrics
}
# Arrondir les valeurs à 3 décimales
models_metrics[,2:5] <- round(models_metrics[,2:5], 3)
# Ajout d'une colonne pour les vrais positifs et négatifs
models_metrics$TP <- sapply(confusion_matrices, function(x) x[2,2])
models_metrics$TN <- sapply(confusion_matrices, function(x) x[1,1])
models_metrics$FP <- sapply(confusion_matrices, function(x) x[1,2])
models_metrics$FN <- sapply(confusion_matrices, function(x) x[2,1])
# Affichage du tableau avec un formatage amélioré
library(knitr)
kable(models_metrics,
col.names = c("Modèle", "Rappel", "Spécificité", "Précision", "TNR",
"Vrais Pos.", "Vrais Nég.", "Faux Pos.", "Faux Nég."),
align = c('l', rep('r', 8)),
caption = "Comparaison des performances des modèles")
# Si vous voulez sauvegarder les résultats dans un fichier CSV
write.csv(models_metrics, "model_comparison_results.csv", row.names = FALSE)
# Création des objets ROC pour chaque modèle
roc_tree1 <- roc(data_ET$defaut, as.numeric(test_tree1))
roc_rp1 <- roc(data_ET$defaut, as.numeric(test_rp1))
roc_rp2 <- roc(data_ET$defaut, as.numeric(test_rp2))
roc_rp3 <- roc(data_ET$defaut, as.numeric(test_rp3))
roc_rp4 <- roc(data_ET$defaut, as.numeric(test_rp4))
roc_tree2 <- roc(data_ET$defaut, as.numeric(test_tree2))
roc_tr1 <- roc(data_ET$defaut, as.numeric(test_tr1))
roc_tr2 <- roc(data_ET$defaut, as.numeric(test_tr2))
roc_tr3 <- roc(data_ET$defaut, as.numeric(test_tr3))
roc_tr4 <- roc(data_ET$defaut, as.numeric(test_tr4))
# Création d'une liste des objets ROC avec leurs noms
roc_list <- list(
tree1 = roc_tree1,
rp1 = roc_rp1,
rp2 = roc_rp2,
rp3 = roc_rp3,
rp4 = roc_rp4,
tree2 = roc_tree2,
tr1 = roc_tr1,
tr2 = roc_tr2,
tr3 = roc_tr3,
tr4 = roc_tr4
)
# Création du dataframe pour ggplot
roc_data <- data.frame()
for(model_name in names(roc_list)) {
roc_obj <- roc_list[[model_name]]
temp_data <- data.frame(
FPR = 1 - roc_obj$specificities,
TPR = roc_obj$sensitivities,
Model = model_name,
AUC = sprintf("%.3f", auc(roc_obj))
)
roc_data <- rbind(roc_data, temp_data)
}
# Création du graphique avec ggplot2
roc_plot <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Model)) +
geom_line(size = 1) +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
labs(
title = "Courbes ROC pour tous les modèles",
x = "Taux de Faux Positifs (1 - Spécificité)",
y = "Taux de Vrais Positifs (Sensibilité)",
color = "Modèle"
) +
theme_minimal() +
theme(
legend.position = "right",
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.text = element_text(size = 10),
axis.title = element_text(size = 12)
)
# Ajout des valeurs AUC dans la légende
roc_plot <- roc_plot +
scale_color_discrete(
labels = paste0(
names(roc_list),
" (AUC = ",
sapply(roc_list, function(x) sprintf("%.3f", auc(x))),
")"
)
)
# Affichage du graphique
print(roc_plot)
# Création d'un tableau des AUC
auc_table <- data.frame(
Model = names(roc_list),
AUC = sapply(roc_list, function(x) round(auc(x), 3))
)
# Tri du tableau par AUC décroissant
auc_table <- auc_table[order(-auc_table$AUC),]
# Affichage du tableau des AUC
print(knitr::kable(auc_table,
col.names = c("Modèle", "AUC"),
caption = "Valeurs AUC pour chaque modèle"))
# Test statistique pour comparer les AUC
# On peut comparer les deux meilleurs modèles par exemple
best_models <- auc_table$Model[1:2]
roc.test(roc_list[[best_models[1]]], roc_list[[best_models[2]]])
# Chargement des donnees a predire dans un data frame 'data_PR'
data_PR <- read.csv("projet_new.csv", sep=",", dec=".", header=T, stringsAsFactors = TRUE)
# Application de l'arbre 'tree1' a l'ensemble de prospects 'data_PR'
# Définir les niveaux dans l'ordre attendu pour la variable education
levels_education <- c("Niveau bac", "Bac+2", "Bac+3", "Bac+4", "Bac+5 et plus")
# Convertir education en facteur ordonné avec les mêmes niveaux
data_PR$education <- factor(data_PR$education, levels = levels_education, ordered = TRUE)
# Convertir categorie en facteur simple
data_PR$categorie <- as.factor(data_PR$categorie)
# Prédiction
class_tree1 <- predict(tree1, data_PR, type = "class")
# Affichqge du tableau des prédictions
table(class_tree1)
data_PR$Prediction <- class_tree1
View(data_PR)
write.table(data_PR, file='resultats.csv', sep="\t", dec=".", row.names = F)
