---
title: "R Poject"
author: "Salah Eddine ABOULKACIM - Marouane TAKI EDINE"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r}
options(repos = c(CRAN = "https://cran.rstudio.com/"))
```

### Analyse exploratoire des données

## Chargement des bibliothèques et des données

```{r}
# Chargement des bibliothèques nécessaires

install.packages("tidyverse")
install.packages("corrplot")
install.packages("ggplot2")
install.packages("gridExtra")
install.packages("knitr")
install.packages("DT")
install.packages("mice")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("C50")
install.packages("tree")
install.packages("DiagrammeR")
install.packages("pROC")
```

```{r}
# Chargement des bibliothèques nécessaires
library(tidyverse)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(knitr)
library(DT)
library(mice)
library(C50)
library(rpart)
library(rpart.plot)
library(tree)
library(DiagrammeR)
library(pROC)
```


```{r}
# Definir le WD

```

```{r}
getwd()
```

```{r}
# Chargement des donnees
data<- read.csv("projet.csv")
```

## Structure des données

```{r}
# Aperçu des données
str(data)
```

```{r}
# Aperçu des données
summary(data)
```

## Prétraitement initial

```{r}
# Conversion des variables en facteurs
data$education <- factor(data$education, 
                        levels = c("Niveau bac", "Bac+2", "Bac+3", "Bac+4", "Bac+5 et plus"),
                        ordered = TRUE)

data$defaut <- factor(data$defaut, 
                     levels = c("Non", "Oui"))

data$categorie <- factor(data$categorie)
```

```{r}
# Conversion des valeurs 999 en NA pour age et adresse
data$age[data$age == 999] <- NA
data$adresse[data$adresse == 999] <- NA
```

## Structure des données après prétraitement

```{r}
# Aperçu des données
str(data)
```

```{r}
# Aperçu des données
summary(data)
```

## Analyse des valeurs manquantes

```{r}
# Vérification des valeurs manquantes
colSums(is.na(data))
```

```{r}
# Calcul des valeurs manquantes
na_counts <- colSums(is.na(data))
na_percentages <- round(100 * na_counts / nrow(data), 2)

# Création d'un dataframe pour l'affichage
missing_data <- data.frame(
  Variable = names(na_counts),
  Compte_NA = na_counts,
  Pourcentage_NA = na_percentages
)

# Affichage avec DT
datatable(missing_data)
```

## Analyse du déséquilibre des classes

```{r}
# Distribution de la variable cible
table(data$defaut)
```

```{r}
# Distribution de la variable cible
prop.table(table(data$defaut))
```

```{r}
# Distribution de la variable cible
class_dist <- table(data$defaut)
class_prop <- prop.table(class_dist) * 100

# Création du graphique
ggplot(data, aes(x = defaut)) +
  geom_bar(fill = "skyblue") +
  labs(title = "Distribution des défauts de paiement",
       x = "Défaut",
       y = "Nombre de clients") +
  theme_minimal()

# Affichage des proportions
kable(data.frame(
  Classe = names(class_dist),
  Compte = as.vector(class_dist),
  Pourcentage = round(as.vector(class_prop), 2)
))
```

## Analyse des valeurs aberrantes

```{r}
numeric_vars <- c("age", "emploi", "adresse", "revenus", "debcred", "debcarte", "autres")
outliers_summary <- list()
for(var in numeric_vars) {
    Q1 <- quantile(data[[var]], 0.25, na.rm = TRUE)
    Q3 <- quantile(data[[var]], 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    lower_bound <- Q1 - 1.5 * IQR
    upper_bound <- Q3 + 1.5 * IQR
    outliers <- sum(data[[var]] < lower_bound | data[[var]] > upper_bound, na.rm = TRUE)
    outliers_pct <- (outliers/sum(!is.na(data[[var]]))) * 100
    outliers_summary[[var]] <- c(count = outliers, percentage = outliers_pct)
}
print("\nPourcentage de valeurs aberrantes par variable:")
outliers_df <- do.call(rbind, outliers_summary)
print(outliers_df)
```

## Analyse bivariée avec la variable cible

```{r}
# Pour les variables numériques
bivariate_stats <- list()
for(var in numeric_vars) {
    stats_by_class <- aggregate(data[[var]], by=list(defaut=data$defaut), 
                              FUN=function(x) c(mean=mean(x, na.rm=TRUE), 
                                              median=median(x, na.rm=TRUE)))
    bivariate_stats[[var]] <- stats_by_class
}
print("Statistiques par classe de défaut:")
print(bivariate_stats)
```

```{r}
# Pour les variables catégorielles
cat_vars <- c("education", "categorie")
for(var in cat_vars) {
    cont_table <- table(data[[var]], data$defaut)
    print(paste("Table de contingence pour", var))
    print(cont_table)
    print(paste("Test du Chi-2 pour", var))
    print(chisq.test(cont_table))
}
```

```{r}
# Corrélations
correlation_matrix <- cor(data[numeric_vars], use = "complete.obs")
print("Matrice de corrélation:")
print(round(correlation_matrix, 3))
```

## Visualisations

```{r}

# Effectuer une imputation multivariée
imputed_data <- mice(data, method = 'pmm', m = 5)

# Choisir l'un des ensembles de données imputées (par exemple, le premier)
data_clean <- complete(imputed_data, 1)

# Distribution de la variable cible
ggplot(data_clean, aes(x = defaut, fill = defaut)) +
    geom_bar() +
    labs(title = "Distribution des défauts de paiement") +
    theme_minimal()

# Boxplots des variables numériques par défaut
for(var in numeric_vars) {
    print(
        ggplot(data_clean, aes_string(x = "defaut", y = var)) +
            geom_boxplot() +
            labs(title = paste("Distribution de", var, "par classe")) +
            theme_minimal()
    )
}

# Visualisation des relations catégorielles
for(var in cat_vars) {
    print(
        ggplot(data_clean, aes_string(x = var, fill = "defaut")) +
            geom_bar(position = "fill") +
            labs(title = paste("Proportion de défauts par", var)) +
            theme_minimal() +
            theme(axis.text.x = element_text(angle = 45, hjust = 1))
    )
}
# Tracer avec les données imputées
ggplot(data_clean, aes(x = age, y = revenus, color = defaut)) +
    geom_point() +
    labs(title = "Nuage de Points de Age et Revenus",
         x = "Valeur de Age",
         y = "Valeur de Revenus") +
    theme_minimal() +
    scale_color_manual(values = c("Non" = "red", "Oui" = "black"))
```


### Clustering des données

## Préparation et exploration pour le clustering
```{r}
# Installation et chargement des packages nécessaires
if(!require(cluster)) install.packages("cluster")
if(!require(factoextra)) install.packages("factoextra")
if(!require(NbClust)) install.packages("NbClust")
library(cluster)
library(factoextra)
library(NbClust)

# Préparation des données pour le clustering
data_clean$education_num <- as.numeric(data_clean$education)

# Sélection des variables pertinentes pour le clustering
vars_clustering <- c("age", "education_num", "emploi", "adresse", "revenus", 
                    "debcred", "debcarte", "autres")
data_cluster <- data_clean[vars_clustering]

# Standardisation des données
data_scaled <- scale(data_cluster)
```


## Détermination du nombre optimal de clusters
```{r}
# Méthode du coude
fviz_nbclust(data_scaled, kmeans, method = "wss", k.max = 10) +
  labs(title = "Méthode du coude pour nombre optimal de clusters")

# Méthode de la silhouette
fviz_nbclust(data_scaled, kmeans, method = "silhouette", k.max = 10) +
  labs(title = "Méthode de la silhouette pour nombre optimal de clusters")

# Test statistique de gap
gap_stat <- clusGap(data_scaled, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 10, iter.max = 100)

fviz_gap_stat(gap_stat) +
  labs(title = "Statistique de gap pour nombre optimal de clusters")
```


## Analyse avec K=2 clusters
```{r}
# K-means avec 2 clusters
set.seed(123)
kmeans_2 <- kmeans(data_scaled, centers = 2, nstart = 25)
data_clean$cluster_2 <- as.factor(kmeans_2$cluster)

# Caractérisation des clusters
cluster_profiles_2 <- data_clean %>%
  group_by(cluster_2) %>%
  summarise(
    Taille = n(),
    Taux_defaut = mean(defaut == "Oui") * 100,
    Age_moyen = mean(age, na.rm = TRUE),
    Age_median = median(age, na.rm = TRUE),
    Revenu_moyen = mean(revenus, na.rm = TRUE),
    Revenu_median = median(revenus, na.rm = TRUE),
    Dette_credit_moyenne = mean(debcred, na.rm = TRUE),
    Dette_carte_moyenne = mean(debcarte, na.rm = TRUE),
    Autres_dettes_moyenne = mean(autres, na.rm = TRUE),
    Emploi_moyen = mean(emploi, na.rm = TRUE)
  )

print("Profils des clusters (K=2):")
print(cluster_profiles_2)

# Visualisations pour K=2
# Distribution des défauts
ggplot(data_clean, aes(x = cluster_2, fill = defaut)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Distribution des défauts par cluster (K=2)",
       x = "Cluster",
       y = "Proportion") +
  theme_minimal()

# Distribution de l'éducation par cluster
ggplot(data_clean, aes(x = education, fill = cluster_2)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Distribution de l'éducation par cluster_2")


# Boîtes à moustaches des variables numériques
variables_num <- c("age", "revenus", "debcred", "debcarte", "autres")
for(var in variables_num) {
  print(
    ggplot(data_clean, aes_string(x = "cluster_2", y = var, fill = "cluster_2")) +
      geom_boxplot() +
      labs(title = paste("Distribution de", var, "par cluster (K=2)")) +
      theme_minimal()
  )
}


# Évaluation statistique pour K=2
print("Tests statistiques pour K=2:")
for(var in variables_num) {
  print(paste("ANOVA pour", var))
  print(summary(aov(as.formula(paste(var, "~ cluster_2")), data = data_clean)))
}

# Calcul de la silhouette pour K=2
sil_2 <- silhouette(kmeans_2$cluster, dist(data_scaled))

# Convertir en dataframe pour ggplot
sil_data_2 <- data.frame(
  cluster = factor(sil_2[, 1]),
  silhouette_width = sil_2[, 3],
  observation = 1:nrow(data_scaled)
)

# Visualisation avec ggplot
ggplot(sil_data_2, aes(x = observation, y = silhouette_width, fill = cluster)) +
  geom_bar(stat = "identity", width = 1) +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Silhouette Plot (K=2)",
    x = "Observation",
    y = "Silhouette Width",
    fill = "Cluster"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_blank())


```



## Analyse avec K=3 clusters
```{r}
# K-means avec 3 clusters
set.seed(123)
kmeans_3 <- kmeans(data_scaled, centers = 3, nstart = 25)
data_clean$cluster_3 <- as.factor(kmeans_3$cluster)

# Caractérisation des clusters
cluster_profiles_3 <- data_clean %>%
  group_by(cluster_3) %>%
  summarise(
    Taille = n(),
    Taux_defaut = mean(defaut == "Oui") * 100,
    Age_moyen = mean(age, na.rm = TRUE),
    Age_median = median(age, na.rm = TRUE),
    Revenu_moyen = mean(revenus, na.rm = TRUE),
    Revenu_median = median(revenus, na.rm = TRUE),
    Dette_credit_moyenne = mean(debcred, na.rm = TRUE),
    Dette_carte_moyenne = mean(debcarte, na.rm = TRUE),
    Autres_dettes_moyenne = mean(autres, na.rm = TRUE),
    Emploi_moyen = mean(emploi, na.rm = TRUE)
  )

print("Profils des clusters (K=3):")
print(cluster_profiles_3)

# Visualisations pour K=3
# Distribution des défauts
ggplot(data_clean, aes(x = cluster_3, fill = defaut)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Distribution des défauts par cluster (K=3)",
       x = "Cluster",
       y = "Proportion") +
  theme_minimal()

# Distribution de l'éducation par cluster
ggplot(data_clean, aes(x = education, fill = cluster_3)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Distribution de l'éducation par cluster_3")


# Boîtes à moustaches des variables numériques
for(var in variables_num) {
  print(
    ggplot(data_clean, aes_string(x = "cluster_3", y = var, fill = "cluster_3")) +
      geom_boxplot() +
      labs(title = paste("Distribution de", var, "par cluster (K=3)")) +
      theme_minimal()
  )
}

# Évaluation statistique pour K=3
print("Tests statistiques pour K=3:")
for(var in variables_num) {
  print(paste("ANOVA pour", var))
  print(summary(aov(as.formula(paste(var, "~ cluster_3")), data = data_clean)))
}

# Calcul de la silhouette pour K=3
sil_3 <- silhouette(kmeans_3$cluster, dist(data_scaled))

# Convertir en dataframe pour ggplot
sil_data_3 <- data.frame(
  cluster = factor(sil_3[, 1]),
  silhouette_width = sil_3[, 3],
  observation = 1:nrow(data_scaled)
)

# Visualisation avec ggplot
ggplot(sil_data_3, aes(x = observation, y = silhouette_width, fill = cluster)) +
  geom_bar(stat = "identity", width = 1) +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Silhouette Plot (K=3)",
    x = "Observation",
    y = "Silhouette Width",
    fill = "Cluster"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_blank())

```




## Analyse avec K=5 clusters
```{r}
# K-means avec 5 clusters
set.seed(123)
kmeans_5 <- kmeans(data_scaled, centers = 5, nstart = 25)
data_clean$cluster_5 <- as.factor(kmeans_5$cluster)

# Caractérisation des clusters
cluster_profiles_5 <- data_clean %>%
  group_by(cluster_5) %>%
  summarise(
    Taille = n(),
    Taux_defaut = mean(defaut == "Oui") * 100,
    Age_moyen = mean(age, na.rm = TRUE),
    Age_median = median(age, na.rm = TRUE),
    Revenu_moyen = mean(revenus, na.rm = TRUE),
    Revenu_median = median(revenus, na.rm = TRUE),
    Dette_credit_moyenne = mean(debcred, na.rm = TRUE),
    Dette_carte_moyenne = mean(debcarte, na.rm = TRUE),
    Autres_dettes_moyenne = mean(autres, na.rm = TRUE),
    Emploi_moyen = mean(emploi, na.rm = TRUE)
  )

print("Profils des clusters (K=5):")
print(cluster_profiles_5)

# Visualisations pour K=5
# Distribution des défauts
ggplot(data_clean, aes(x = cluster_5, fill = defaut)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Distribution des défauts par cluster (K=5)",
       x = "Cluster",
       y = "Proportion") +
  theme_minimal()

# Distribution de l'éducation par cluster
ggplot(data_clean, aes(x = education, fill = cluster_5)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Distribution de l'éducation par cluster_5")


# Boîtes à moustaches des variables numériques
for(var in variables_num) {
  print(
    ggplot(data_clean, aes_string(x = "cluster_5", y = var, fill = "cluster_5")) +
      geom_boxplot() +
      labs(title = paste("Distribution de", var, "par cluster (K=5)")) +
      theme_minimal()
  )
}

# Évaluation statistique pour K=5
print("Tests statistiques pour K=5:")
for(var in variables_num) {
  print(paste("ANOVA pour", var))
  print(summary(aov(as.formula(paste(var, "~ cluster_5")), data = data_clean)))
}

# Calcul de la silhouette
sil_5 <- silhouette(kmeans_5$cluster, dist(data_scaled))

# Convertir en dataframe pour ggplot
sil_data <- data.frame(
  cluster = factor(sil_5[, 1]),
  silhouette_width = sil_5[, 3],
  observation = 1:nrow(data_scaled)
)

# Visualisation avec ggplot
ggplot(sil_data, aes(x = observation, y = silhouette_width, fill = cluster)) +
  geom_bar(stat = "identity", width = 1) +
  scale_fill_brewer(palette = "Set3") +
  labs(
    title = "Silhouette Plot (K=5)",
    x = "Observation",
    y = "Silhouette Width",
    fill = "Cluster"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_blank())
```

## Évaluation statistique des différences entre clusters

```{r}
# Tests de Kruskal-Wallis pour toutes les variables numériques
variables_test <- c("age", "revenus", "debcred", "debcarte", "autres", "emploi")

# Fonction pour faire tous les tests statistiques
run_statistical_tests <- function(data, cluster_var) {
  results <- list()
  
  # Tests Kruskal-Wallis
  for(var in variables_test) {
    formula <- as.formula(paste(var, "~", cluster_var))
    test_result <- kruskal.test(formula, data = data)
    results[[paste("kruskal", var)]] <- test_result
  }
  
  # Test Chi-carré pour variables catégorielles
  chi_education <- chisq.test(table(data$education, data[[cluster_var]]))
  chi_defaut <- chisq.test(table(data$defaut, data[[cluster_var]]))
  
  results[["chi_education"]] <- chi_education
  results[["chi_defaut"]] <- chi_defaut
  
  return(results)
}

# Exécution des tests pour K=2, K=3 et K=5
results_k2 <- run_statistical_tests(data_clean, "cluster_2")
results_k3 <- run_statistical_tests(data_clean, "cluster_3")
results_k5 <- run_statistical_tests(data_clean, "cluster_5")
```


## Analyse comparative approfondie

```{r}
comparative_analysis <- data.frame(
  K = rep(c(2, 3, 5), each = length(variables_test)),
  Variable = rep(variables_test, 3),
  Kruskal_pvalue = c(
    sapply(results_k2[grep("kruskal", names(results_k2))], function(x) x$p.value),
    sapply(results_k3[grep("kruskal", names(results_k3))], function(x) x$p.value),
    sapply(results_k5[grep("kruskal", names(results_k5))], function(x) x$p.value)
  )
)

# Validation de la qualité des clusters
cluster_quality <- data.frame(
  K = c(2, 3, 5),
  Within_SS = c(kmeans_2$tot.withinss, kmeans_3$tot.withinss, kmeans_5$tot.withinss),
  Between_SS = c(kmeans_2$betweenss, kmeans_3$betweenss, kmeans_5$betweenss),
  Total_SS = c(kmeans_2$totss, kmeans_3$totss, kmeans_5$totss),
  Silhouette = c(mean(sil_2[,3]), mean(sil_3[,3]), mean(sil_5[,3]))
)

# Calcul des ratios de variance expliquée
cluster_quality$Explained_Variance_Ratio <- cluster_quality$Between_SS / cluster_quality$Total_SS
```

## Comparaison des différentes configurations

```{r}
cluster_comparison <- data.frame(
  K = c(2, 3, 5),
  Clusters_Size_Range = c(
    paste(range(table(data_clean$cluster_2)), collapse="-"),
    paste(range(table(data_clean$cluster_3)), collapse="-"),
    paste(range(table(data_clean$cluster_5)), collapse="-")
  ),
  Defaut_Rate_Range = c(
    paste(range(round(cluster_profiles_2$Taux_defaut, 2)), collapse="-"),
    paste(range(round(cluster_profiles_3$Taux_defaut, 2)), collapse="-"),
    paste(range(round(cluster_profiles_5$Taux_defaut, 2)), collapse="-")
  ),
  Silhouette_Score = round(cluster_quality$Silhouette, 3),
  Explained_Variance = round(cluster_quality$Explained_Variance_Ratio, 3)
)

# Affichage des résultats
print("Analyse comparative des configurations de clustering:")
print(cluster_comparison)

print("\nTests statistiques significatifs (p < 0.05):")
print(subset(comparative_analysis, Kruskal_pvalue < 0.05))

print("\nQualité des clusters:")
print(cluster_quality)
```

## Visualisation

```{r}
# Visualisation comparative des silhouettes
ggplot(cluster_quality, aes(x = as.factor(K), y = Silhouette)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Comparaison des scores de silhouette",
       x = "Nombre de clusters (K)",
       y = "Score de silhouette moyen") +
  theme_minimal()

# Visualisation de la variance expliquée
ggplot(cluster_quality, aes(x = as.factor(K), y = Explained_Variance_Ratio)) +
  geom_bar(stat = "identity", fill = "darkred") +
  labs(title = "Ratio de variance expliquée par configuration",
       x = "Nombre de clusters (K)",
       y = "Ratio de variance expliquée") +
  theme_minimal()
```


### Apprentissage (Rpart et tree)

## Creation des ensembles d'apprentissage et de test

```{r}
# Ensemble d'apprentissage de 80% du data
data_EA<- data[1:4800,]

# Ensemble de test de 20% du data
data_ET<- data[4801:6000,]

```

```{r}
# Suppression de la variable client (variable unique)
data_EA <- subset(data_EA, select=-client)
```

## APPRENTISSAGE ARBRE DE DECISION 'rpart' sans paramétrage

```{r}
# Apprentissage arbre
tree1 <- rpart(defaut~., data_EA)

# Affichage graphique : tracage des arcs par la fonction plot.rpart() 
plot(tree1)

# Ajout du texte au graphique par la fonction text.rpart()
text(tree1, pretty = 0)

# affichage avec la librairie rpart.plot
rpart.plot(tree1, cex=0.6)
```

## APPRENTISSAGE ARBRE DE DECISION 'rpart' avec paramétrage

```{r}
# Selection d'attribut par Coefficient de Gini et effectif minimal d'un noeud de 10
tree_rp1 <- rpart(defaut~., data_EA, parms = list(split = "gini"), control = rpart.control(minbucket = 10))
plot(tree_rp1)
text(tree_rp1, pretty = 0)

# Selection d'attribut par Coefficient de Gini et effectif minimal d'un noeud de 5
tree_rp2 <- rpart(defaut~., data_EA, parms = list(split = "gini"), control = rpart.control(minbucket = 5))
plot(tree_rp2)
text(tree_rp2, pretty = 0)

# Selection d'attribut par Information Gain et effectif minimal d'un noeud de 10
tree_rp3 <- rpart(defaut~., data_EA, parms = list(split = "information"), control = rpart.control(minbucket = 10))
plot(tree_rp3)
text(tree_rp3, pretty = 0)

# Selection d'attribut par Information Gain et effectif minimal d'un noeud de 5
tree_rp4 <- rpart(defaut~., data_EA, parms = list(split = "information"), control = rpart.control(minbucket = 5))
plot(tree_rp4)
text(tree_rp4, pretty = 0)

# Affichage des arbres rpart() avec rpart.plot() pour plus de lisibilité
rpart.plot(tree_rp1)
rpart.plot(tree_rp2, cex=0.7)
rpart.plot(tree_rp3)
rpart.plot(tree_rp4, cex=0.7)
```

## APPRENTISSAGE ARBRE DE DECISION 'tree' sans paramétrage

```{r}
# Apprentissage arbre
tree2 <- tree(defaut~., data=data_EA)

# Affichage graphique : tracage des arcs par la fonction plot.tree() 
plot(tree2)
# Ajout du texte au graphique par la fonction text.tree()
text(tree2, pretty=0)
```

## APPRENTISSAGE ARBRE DE DECISION 'tree' avec paramétrage

```{r}
# Apprentissage 1er parametrage pour tree()
tree_tr1 <- tree(defaut~., data_EA, split = "deviance", control = tree.control(nrow(data_EA), mincut = 10))
plot(tree_tr1)
text(tree_tr1, pretty = 0)

# Apprentissage 2nd parametrage pour tree()
tree_tr2 <- tree(defaut~., data_EA, split = "deviance", control = tree.control(nrow(data_EA), mincut = 5))
plot(tree_tr2)
text(tree_tr2, pretty = 0)

# Apprentissage 3eme parametrage pour tree() / overlapping text, making it unreadable. The tree has too many splits and the nodes are very close to each other
tree_tr3 <- tree(defaut~., data_EA, split = "gini", control = tree.control(nrow(data_EA), mincut = 10))
plot(tree_tr3)
text(tree_tr3, pretty = 0)

# Apprentissage 4eme parametrage pour tree()
tree_tr4 <- tree(defaut~., data_EA, split = "gini", control = tree.control(nrow(data_EA), mincut = 5))
plot(tree_tr4)
text(tree_tr4, pretty = 0)

```

### TEST DES DES CLASSIFIEURS (Rpart et tree)

## Test des arbes

```{r}
##  Rpart cases
# Sans paramétrage

# Application de l'arbre 'tree1' a l'ensemble de test 'data_ET'
test_tree1 <- predict(tree1, data_ET, type="class")

# Avec paramétrage
# Application de l'arbre 'tree_rp1' a l'ensemble de test 'data_ET' 
test_rp1 <- predict(tree_rp1, data_ET, type="class")
# Application de l'arbre 'tree_rp2' a l'ensemble de test 'data_ET'
test_rp2 <- predict(tree_rp2, data_ET, type="class")
# Application de l'arbre 'tree_rp3' a l'ensemble de test 'data_ET' 
test_rp3 <- predict(tree_rp3, data_ET, type="class")
# Application de l'arbre 'tree_rp4' a l'ensemble de test 'data_ET'
test_rp4 <- predict(tree_rp4, data_ET, type="class")
```

```{r}
## tree cases

# Sans paramétrage
# Application de l'arbre 'tree2' a l'ensemble de test 'data_ET'
test_tree2 <- predict(tree2, data_ET, type="class")

# Avec paramétrage
# Test  1
test_tr1 <- predict(tree_tr1, data_ET, type="class")
# Test  2
test_tr2 <- predict(tree_tr2, data_ET, type="class")
# Test  3
test_tr3 <- predict(tree_tr3, data_ET, type="class")
# Test  4
test_tr4 <- predict(tree_tr4, data_ET, type="class")
```

```{r}
# Comparaison des repartitions des predictions
table(test_tree1)
table(test_rp1)
table(test_rp2)
table(test_rp3)
table(test_rp4)
table(test_tree2)
table(test_tr1)
table(test_tr2)
table(test_tr3)
table(test_tr4)
```

```{r}
# Créer des tables pour chaque ensemble de prédictions
table_tree1 <- table(test_tree1)
table_rp1 <- table(test_rp1)
table_rp2 <- table(test_rp2)
table_rp3 <- table(test_rp3)
table_rp4 <- table(test_rp4)
table_tree2 <- table(test_tree2)
table_tr1 <- table(test_tr1)
table_tr2 <- table(test_tr2)
table_tr3 <- table(test_tr3)
table_tr4 <- table(test_tr4)

# Combiner les résultats dans un dataframe
results <- data.frame(
  Test = c("test_tree1", "test_rp1", "test_rp2", "test_rp3", "test_rp4", "test_tree2", "test_tr1", "test_tr2", "test_tr3", "test_tr4"),
  Non = c(table_tree1["Non"], table_rp1["Non"], table_rp2["Non"], table_rp3["Non"], table_rp4["Non"], table_tree2["Non"], table_tr1["Non"], table_tr2["Non"], table_tr3["Non"], table_tr4["Non"]),
  Oui = c(table_tree1["Oui"], table_rp1["Oui"], table_rp2["Oui"], table_rp3["Oui"], table_rp4["Oui"], table_tree2["Oui"], table_tr1["Oui"], table_tr2["Oui"], table_tr3["Oui"], table_tr4["Oui"])
)

# Afficher le tableau
print(results)
```

### Evaluation et choix du meilleure modèle

## Calcul des taux de succès

```{r}
# Rpart cases
taux_tree1 <- nrow(data_ET[data_ET$defaut == test_tree1, ]) / nrow(data_ET)
taux_rp1 <- nrow(data_ET[data_ET$defaut == test_rp1, ]) / nrow(data_ET)
taux_rp2 <- nrow(data_ET[data_ET$defaut == test_rp2, ]) / nrow(data_ET)
taux_rp3 <- nrow(data_ET[data_ET$defaut == test_rp3, ]) / nrow(data_ET)
taux_rp4 <- nrow(data_ET[data_ET$defaut == test_rp4, ]) / nrow(data_ET)

cat("Taux pour test_tree1:", taux_tree1, "\n")
cat("Taux pour test_rp1:", taux_rp1, "\n")
cat("Taux pour test_rp2:", taux_rp2, "\n")
cat("Taux pour test_rp3:", taux_rp3, "\n")
cat("Taux pour test_rp4:", taux_rp4, "\n")

# Tree cases
taux_tree2 <- nrow(data_ET[data_ET$defaut == test_tree2, ]) / nrow(data_ET)
taux_tr1 <- nrow(data_ET[data_ET$defaut == test_tr1, ]) / nrow(data_ET)
taux_tr2 <- nrow(data_ET[data_ET$defaut == test_tr2, ]) / nrow(data_ET)
taux_tr3 <- nrow(data_ET[data_ET$defaut == test_tr3, ]) / nrow(data_ET)
taux_tr4 <- nrow(data_ET[data_ET$defaut == test_tr4, ]) / nrow(data_ET)

cat("Taux pour test_tree2:", taux_tree2, "\n")
cat("Taux pour test_tr1:", taux_tr1, "\n")
cat("Taux pour test_tr2:", taux_tr2, "\n")
cat("Taux pour test_tr3:", taux_tr3, "\n")
cat("Taux pour test_tr4:", taux_tr4, "\n")

```

## Matrice de confusion

```{r}
# Matrice de confusion pour 'tree1'
mc_tree1 <- table(data_ET$defaut, test_tree1)
print(mc_tree1)
# Rappel
mc_tree1[2,2]/(mc_tree1[2,2]+mc_tree1[2,1])
# Spécificité
mc_tree1[1,1]/(mc_tree1[1,1]+mc_tree1[1,2])
# Précision 
mc_tree1[2,2]/(mc_tree1[2,2]+mc_tree1[1,2])
# Taux de Vrais Négatifs 
mc_tree1[1,1]/(mc_tree1[1,1]+mc_tree1[2,1])

# Matrice de confusion pour 'test_rp1'
mc_rp1 <- table(data_ET$defaut, test_rp1)
print(mc_rp1)
# Rappel
mc_rp1[2,2]/(mc_rp1[2,2]+mc_rp1[2,1])
# Spécificité
mc_rp1[1,1]/(mc_rp1[1,1]+mc_rp1[1,2])
# Précision 
mc_rp1[2,2]/(mc_rp1[2,2]+mc_rp1[1,2])
# Taux de Vrais Négatifs 
mc_rp1[1,1]/(mc_rp1[1,1]+mc_rp1[2,1])

# Matrice de confusion pour 'test_rp2'
mc_rp2 <- table(data_ET$defaut, test_rp2)
print(mc_rp2)
# Rappel
mc_rp2[2,2]/(mc_rp2[2,2]+mc_rp2[2,1])
# Spécificité
mc_rp2[1,1]/(mc_rp2[1,1]+mc_rp2[1,2])
# Précision 
mc_rp2[2,2]/(mc_rp2[2,2]+mc_rp2[1,2])
# Taux de Vrais Négatifs 
mc_rp2[1,1]/(mc_rp2[1,1]+mc_rp2[2,1])

# Matrice de confusion pour 'test_rp3'
mc_rp3 <- table(data_ET$defaut, test_rp3)
print(mc_rp3)
# Rappel
mc_rp3[2,2]/(mc_rp3[2,2]+mc_rp3[2,1])
# Spécificité
mc_rp3[1,1]/(mc_rp3[1,1]+mc_rp3[1,2])
# Précision 
mc_rp3[2,2]/(mc_rp3[2,2]+mc_rp3[1,2])
# Taux de Vrais Négatifs 
mc_rp3[1,1]/(mc_rp3[1,1]+mc_rp3[2,1])

# Matrice de confusion pour 'test_rp4'
mc_rp4 <- table(data_ET$defaut, test_rp4)
print(mc_rp4)
# Rappel
mc_rp4[2,2]/(mc_rp4[2,2]+mc_rp4[2,1])
# Spécificité
mc_rp4[1,1]/(mc_rp4[1,1]+mc_rp4[1,2])
# Précision 
mc_rp4[2,2]/(mc_rp4[2,2]+mc_rp4[1,2])
# Taux de Vrais Négatifs 
mc_rp4[1,1]/(mc_rp4[1,1]+mc_rp4[2,1])

# Matrice de confusion pour 'test_tree2'
mc_tree2 <- table(data_ET$defaut, test_tree2)
print(mc_tree2)
# Rappel
mc_tree2[2,2]/(mc_tree2[2,2]+mc_tree2[2,1])
# Spécificité
mc_tree2[1,1]/(mc_tree2[1,1]+mc_tree2[1,2])
# Précision 
mc_tree2[2,2]/(mc_tree2[2,2]+mc_tree2[1,2])
# Taux de Vrais Négatifs 
mc_tree2[1,1]/(mc_tree2[1,1]+mc_tree2[2,1])

# Matrice de confusion pour 'test_tr1'
mc_tr1 <- table(data_ET$defaut, test_tr1)
print(mc_tr1)
# Rappel
mc_tr1[2,2]/(mc_tr1[2,2]+mc_tr1[2,1])
# Spécificité
mc_tr1[1,1]/(mc_tr1[1,1]+mc_tr1[1,2])
# Précision 
mc_tr1[2,2]/(mc_tr1[2,2]+mc_tr1[1,2])
# Taux de Vrais Négatifs 
mc_tr1[1,1]/(mc_tr1[1,1]+mc_tr1[2,1])

# Matrice de confusion pour 'test_tr2'
mc_tr2 <- table(data_ET$defaut, test_tr2)
print(mc_tr2)
# Rappel
mc_tr2[2,2]/(mc_tr2[2,2]+mc_tr2[2,1])
# Spécificité
mc_tr2[1,1]/(mc_tr2[1,1]+mc_tr2[1,2])
# Précision 
mc_tr2[2,2]/(mc_tr2[2,2]+mc_tr2[1,2])
# Taux de Vrais Négatifs 
mc_tr2[1,1]/(mc_tr2[1,1]+mc_tr2[2,1])

# Matrice de confusion pour 'test_tr3'
mc_tr3 <- table(data_ET$defaut, test_tr3)
print(mc_tr3)
# Rappel
mc_tr3[2,2]/(mc_tr3[2,2]+mc_tr3[2,1])
# Spécificité
mc_tr3[1,1]/(mc_tr3[1,1]+mc_tr3[1,2])
# Précision 
mc_tr3[2,2]/(mc_tr3[2,2]+mc_tr3[1,2])
# Taux de Vrais Négatifs 
mc_tr3[1,1]/(mc_tr3[1,1]+mc_tr3[2,1])

# Matrice de confusion pour 'test_tr4'
mc_tr4 <- table(data_ET$defaut, test_tr4)
print(mc_tr4)
# Rappel
mc_tr4[2,2]/(mc_tr4[2,2]+mc_tr4[2,1])
# Spécificité
mc_tr4[1,1]/(mc_tr4[1,1]+mc_tr4[1,2])
# Précision 
mc_tr4[2,2]/(mc_tr4[2,2]+mc_tr4[1,2])
# Taux de Vrais Négatifs 
mc_tr4[1,1]/(mc_tr4[1,1]+mc_tr4[2,1])

```

```{r}
# Création d'une fonction pour calculer les métriques
calculate_metrics <- function(confusion_matrix) {
  recall <- confusion_matrix[2,2] / (confusion_matrix[2,2] + confusion_matrix[2,1])
  specificity <- confusion_matrix[1,1] / (confusion_matrix[1,1] + confusion_matrix[1,2])
  precision <- confusion_matrix[2,2] / (confusion_matrix[2,2] + confusion_matrix[1,2])
  tnr <- confusion_matrix[1,1] / (confusion_matrix[1,1] + confusion_matrix[2,1])
  
  return(c(recall, specificity, precision, tnr))
}

# Création du dataframe avec tous les résultats
models_metrics <- data.frame(
  Model = c("tree1", "rp1", "rp2", "rp3", "rp4", 
            "tree2", "tr1", "tr2", "tr3", "tr4"),
  Recall = NA,
  Specificity = NA,
  Precision = NA,
  TNR = NA
)

# Liste des matrices de confusion
confusion_matrices <- list(
  mc_tree1, mc_rp1, mc_rp2, mc_rp3, mc_rp4,
  mc_tree2, mc_tr1, mc_tr2, mc_tr3, mc_tr4
)

# Remplissage du dataframe avec les métriques
for(i in 1:length(confusion_matrices)) {
  metrics <- calculate_metrics(confusion_matrices[[i]])
  models_metrics[i, 2:5] <- metrics
}

# Arrondir les valeurs à 3 décimales
models_metrics[,2:5] <- round(models_metrics[,2:5], 3)

# Ajout d'une colonne pour les vrais positifs et négatifs
models_metrics$TP <- sapply(confusion_matrices, function(x) x[2,2])
models_metrics$TN <- sapply(confusion_matrices, function(x) x[1,1])
models_metrics$FP <- sapply(confusion_matrices, function(x) x[1,2])
models_metrics$FN <- sapply(confusion_matrices, function(x) x[2,1])

# Affichage du tableau avec un formatage amélioré
library(knitr)
kable(models_metrics, 
      col.names = c("Modèle", "Rappel", "Spécificité", "Précision", "TNR", 
                    "Vrais Pos.", "Vrais Nég.", "Faux Pos.", "Faux Nég."),
      align = c('l', rep('r', 8)),
      caption = "Comparaison des performances des modèles")

# Si vous voulez sauvegarder les résultats dans un fichier CSV
write.csv(models_metrics, "model_comparison_results.csv", row.names = FALSE)
```

##  Graphique ROC

```{r}
# Création des objets ROC pour chaque modèle
roc_tree1 <- roc(data_ET$defaut, as.numeric(test_tree1))
roc_rp1 <- roc(data_ET$defaut, as.numeric(test_rp1))
roc_rp2 <- roc(data_ET$defaut, as.numeric(test_rp2))
roc_rp3 <- roc(data_ET$defaut, as.numeric(test_rp3))
roc_rp4 <- roc(data_ET$defaut, as.numeric(test_rp4))
roc_tree2 <- roc(data_ET$defaut, as.numeric(test_tree2))
roc_tr1 <- roc(data_ET$defaut, as.numeric(test_tr1))
roc_tr2 <- roc(data_ET$defaut, as.numeric(test_tr2))
roc_tr3 <- roc(data_ET$defaut, as.numeric(test_tr3))
roc_tr4 <- roc(data_ET$defaut, as.numeric(test_tr4))

# Création d'une liste des objets ROC avec leurs noms
roc_list <- list(
  tree1 = roc_tree1,
  rp1 = roc_rp1,
  rp2 = roc_rp2,
  rp3 = roc_rp3,
  rp4 = roc_rp4,
  tree2 = roc_tree2,
  tr1 = roc_tr1,
  tr2 = roc_tr2,
  tr3 = roc_tr3,
  tr4 = roc_tr4
)

# Création du dataframe pour ggplot
roc_data <- data.frame()
for(model_name in names(roc_list)) {
  roc_obj <- roc_list[[model_name]]
  temp_data <- data.frame(
    FPR = 1 - roc_obj$specificities,
    TPR = roc_obj$sensitivities,
    Model = model_name,
    AUC = sprintf("%.3f", auc(roc_obj))
  )
  roc_data <- rbind(roc_data, temp_data)
}

# Création du graphique avec ggplot2
roc_plot <- ggplot(roc_data, aes(x = FPR, y = TPR, color = Model)) +
  geom_line(size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
  labs(
    title = "Courbes ROC pour tous les modèles",
    x = "Taux de Faux Positifs (1 - Spécificité)",
    y = "Taux de Vrais Positifs (Sensibilité)",
    color = "Modèle"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 12)
  )

# Ajout des valeurs AUC dans la légende
roc_plot <- roc_plot +
  scale_color_discrete(
    labels = paste0(
      names(roc_list), 
      " (AUC = ", 
      sapply(roc_list, function(x) sprintf("%.3f", auc(x))),
      ")"
    )
  )

# Affichage du graphique
print(roc_plot)

# Création d'un tableau des AUC
auc_table <- data.frame(
  Model = names(roc_list),
  AUC = sapply(roc_list, function(x) round(auc(x), 3))
)

# Tri du tableau par AUC décroissant
auc_table <- auc_table[order(-auc_table$AUC),]

# Affichage du tableau des AUC
print(knitr::kable(auc_table, 
                   col.names = c("Modèle", "AUC"),
                   caption = "Valeurs AUC pour chaque modèle"))

# Test statistique pour comparer les AUC
# On peut comparer les deux meilleurs modèles par exemple
best_models <- auc_table$Model[1:2]
roc.test(roc_list[[best_models[1]]], roc_list[[best_models[2]]])
```
### PREDICTIONS DU CLASSIFIEUR SELECTIONNE

```{r}
# Chargement des donnees a predire dans un data frame 'data_PR'
data_PR <- read.csv("projet_new.csv", sep=",", dec=".", header=T, stringsAsFactors = TRUE)
```

```{r}
# Application de l'arbre 'tree1' a l'ensemble de prospects 'data_PR' 

# Définir les niveaux dans l'ordre attendu pour la variable education
levels_education <- c("Niveau bac", "Bac+2", "Bac+3", "Bac+4", "Bac+5 et plus")

# Convertir education en facteur ordonné avec les mêmes niveaux
data_PR$education <- factor(data_PR$education, levels = levels_education, ordered = TRUE)

# Convertir categorie en facteur simple
data_PR$categorie <- as.factor(data_PR$categorie)

# Prédiction
class_tree1 <- predict(tree1, data_PR, type = "class")

# Affichqge du tableau des prédictions
table(class_tree1)

```
```{r}
data_PR$Prediction <- class_tree1
View(data_PR)
```


```{r}
write.table(data_PR, file='resultats.csv', sep="\t", dec=".", row.names = F)
```

